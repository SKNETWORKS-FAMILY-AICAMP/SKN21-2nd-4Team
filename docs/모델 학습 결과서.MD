# 🤖 모델 학습 결과서
**Dataset:** Telco Customer Churn  
**Author:** 우재현, 김승룡  
**Last Updated:** 2025-11-25     


---
<br>

# 1. 최종 모델 선정을 위한 평가 지표와 그에 대한 설명

**평가 지표 선정 이유**
- Recall: 실제 이탈자를 정확하게 예측이 필요하기에 중요한 평가지표.
- Precision: 이탈 모델에서 이탈자를 잘못 파악 시 비용낭비가 발생할 수 있다.
- F1-score: Recall과 Precision 모두 중요 지표이기에 조화 평균인 F1-score를 1차 지표로 선정. 우선적으로 판단.
- Accuracy: 보조지표로 활용 예정

**종합 의사 결정 기준**
> F1-score, Recall, Precision, Accuracy 순으로 선정.
- 서비스 이용자가 통신사의 관리자이기에, 누가 실제로 이탈할 지를 놓치지 않는 것이 중요하다 생각하여, Recall을 Precision보다 더 중요한 지표로 판단한다.

- F1-score가 비슷하다면 Recall 0.75 이상을 우선 기준으로 삼고,
Recall 0.80 이상을 달성한 모델은 우수 모델로 판단한다.

<br>

# 2. 최종 선정 된 모델에 대한 설명
최종 선정된 모델 : XGBoost<br>
XGBoost가 분류 문제에 널리 사용되는 주요 이유는 뛰어난 예측 성능과 효율성 및 다양한 기능을 모두 갖추고 있기 때문입니다. 
> 뛰어난 예측 성능 
- 부스팅 앙상블 기법: XGBoost는 여러 개의 약한 학습기(주로 결정 트리)를 순차적으로 결합하여 이전 모델의 오류를 보완하며 학습하는 부스팅(Boosting) 알고리즘을 기반으로 합니다. 이를 통해 매우 강력한 예측 모델을 구축할 수 있습니다.
- 과적합 방지 (규제): 표준 GBM(Gradient Boosting Machine)과 달리, XGBoost 자체에는 L1(Lasso), L2(Ridge) 규제 기능이 포함되어 있어 모델의 복잡도를 제어하고 과적합을 효과적으로 방지합니다. 이는 모델의 일반화 성능을 높여줍니다.
- 다양한 문제 해결: 분류(classification)뿐만 아니라 회귀(regression) 문제에서도 뛰어난 성능을 발휘하며, 데이터의 종류나 크기에 관계없이 강력한 예측력을 보입니다. 
> 효율성 및 다양한 기능
- 빠른 수행 시간: 병렬 처리 기능을 지원하여 GBM 대비 학습 및 분류 속도가 현저히 빠릅니다.
- 결측치 자체 처리: 데이터에 포함된 결측치(missing values)를 알고리즘 내부적으로 처리할 수 있어, 별도의 복잡한 결측치 전처리 과정이 줄어듭니다. -> 하지만 별도로 결측치 처리를 미리 함.
- 유연성: 다양한 하이퍼파라미터 튜닝 옵션을 제공하여 특정 데이터셋과 문제에 맞게 모델을 세밀하게 조정할 수 있습니다. 

<br>

# 3. 학습 과정 기록
사용 모델 : DecisionTree, RandomForest, LogisticRegression, LGBM, XGBoost, SVM

![alt text](img/image-8.png)
모델 별 Accuracy, F1-score, Recall, Precision plot

![alt text](img/image-9.png)
모델 별 ROC curve와 AUC score
<br>

![alt text](img/RECALLnPrecision.png)
![alt text](img/ACCnF1.png)

평가지표 별 최고 모델

- 하이퍼파라미터 튜닝 과정에 대한 설명
1. 인코딩 된 Impute 파일 선택
2. 모델 별 train/validation/test 셋으로 훈련
3. feature importance 와 permutation_importance 확인
4. feature selection 진행하며 성능 비교
5. 모델별로 다르게 하이퍼파라미터 튜닝(GridSearchCV and Optuna)
6. 튜닝한 하이퍼파라미터를 적용하여 2~4과정 다시 진행
7. threshold 조정
8. 모델 별 성능 비교로 최고 모델 선택<br><br>

최종 모델과 최종 평가 지표에 대해 기술<br>

결측치 처리 방법으로 4가지 방법을 적용해서 각 모델별로 테스트 한 결과 SimpleImputer - Median이 가장 성능이 좋았음.<br>
> 사용한 결측치 처리 방법
1. KNN
2. SimpleImputer - Frequent
3. SimpleImputer - Median
4. 0으로 대치<br>

> XGboost를 최종 모델로 설정<br>
1. F1-score는 LGBM과 XGboost가 비슷하게 높음<br>
2. recall이 XGboost가 LGBM보다 높음.<br>

> XGboost를 Optuna로 하이퍼파라미터 튜닝 후, 지표들
1. 정확도: 0.8540601930721181<br>
2. F1 점수: 0.765296803652968<br>
3. 재현율: 0.8972162740899358<br>
4. 정밀도: 0.6671974522292994<br>
5. Average Precision: 0.8292267171344867<br>
6. ROC-AUC Score: 0.929282407024349

<br>


# 최종 모델과 Service application
- **최종 모델**  - models/XGB_model.pkl

- **Service application** - streamlit_py/

